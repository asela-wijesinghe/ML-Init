{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass   education   education-num       marital-status  \\\n",
       "0   39          State-gov   Bachelors              13        Never-married   \n",
       "1   50   Self-emp-not-inc   Bachelors              13   Married-civ-spouse   \n",
       "2   38            Private     HS-grad               9             Divorced   \n",
       "3   53            Private        11th               7   Married-civ-spouse   \n",
       "4   28            Private   Bachelors              13   Married-civ-spouse   \n",
       "\n",
       "           occupation    relationship    race      sex   capital-gain  \\\n",
       "0        Adm-clerical   Not-in-family   White     Male           2174   \n",
       "1     Exec-managerial         Husband   White     Male              0   \n",
       "2   Handlers-cleaners   Not-in-family   White     Male              0   \n",
       "3   Handlers-cleaners         Husband   Black     Male              0   \n",
       "4      Prof-specialty            Wife   Black   Female              0   \n",
       "\n",
       "    capital-loss   hours-per-week  native-country  income  \n",
       "0              0               40   United-States   <=50K  \n",
       "1              0               13   United-States   <=50K  \n",
       "2              0               40   United-States   <=50K  \n",
       "3              0               40   United-States   <=50K  \n",
       "4              0               40            Cuba   <=50K  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# Read dataset to pandas dataframe\n",
    "dataset = pd.read_csv(\"data.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How to pre-process the data?\n",
    "# fix dataset\n",
    "# 0,4,9,10,11 is continous so select only descrete columns\n",
    "cat_columns = []\n",
    "for i in [1,2,4,5,6,7,8,12,13]:\n",
    "    cat_columns.append(dataset.columns[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace empty values\n",
    "dataset = dataset.replace(\" ?\", pd.NaT)\n",
    "dataset.dropna(inplace=True)\n",
    "#dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                int64\n",
       " workclass          int8\n",
       " education          int8\n",
       " education-num     int64\n",
       " marital-status     int8\n",
       " occupation         int8\n",
       " relationship       int8\n",
       " race               int8\n",
       " sex                int8\n",
       " capital-gain      int64\n",
       " capital-loss      int64\n",
       " hours-per-week    int64\n",
       " native-country     int8\n",
       " income             int8\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in cat_columns:\n",
    "    dataset[i] = dataset[i].astype('category')\n",
    "    \n",
    " # represet them using numerical values\n",
    "for i in cat_columns:\n",
    "    dataset[i] = pd.Categorical(dataset[i]).codes\n",
    "    \n",
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((13, len(dataset)))\n",
    "y = np.array(dataset[dataset.columns[13]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign values to the array\n",
    "for i in range(len(dataset.columns)-1):\n",
    "    X[i] = np.array(dataset[dataset.columns[i]])\n",
    "X = X.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to handle the over-fitting problem?\n",
    "# setting testing and training data limit\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training and predictions\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# predict test data\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4117  416]\n",
      " [ 564  936]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.91      0.89      4533\n",
      "          1       0.69      0.62      0.66      1500\n",
      "\n",
      "avg / total       0.83      0.84      0.83      6033\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# How to compare the designed machine learning models?\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs\n",
    "epochs = 100\n",
    "batch_size = 88\n",
    "output_classes = 2\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, output_classes)\n",
    "y_test = np_utils.to_categorical(y_test, output_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 2)                 28        \n",
      "=================================================================\n",
      "Total params: 28\n",
      "Trainable params: 28\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 2)                 28        \n",
      "=================================================================\n",
      "Total params: 28\n",
      "Trainable params: 28\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "24129/24129 [==============================] - 0s 17us/step - loss: 4.0049 - acc: 0.7498\n",
      "Epoch 2/100\n",
      "24129/24129 [==============================] - 0s 11us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 3/100\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 4/100\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 5/100\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 6/100\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 7/100\n",
      "24129/24129 [==============================] - 0s 16us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 8/100\n",
      "24129/24129 [==============================] - 0s 15us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 9/100\n",
      "24129/24129 [==============================] - 0s 13us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 10/100\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 11/100\n",
      "24129/24129 [==============================] - 0s 13us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 12/100\n",
      "24129/24129 [==============================] - 0s 15us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 13/100\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 14/100\n",
      "24129/24129 [==============================] - 0s 11us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 15/100\n",
      "24129/24129 [==============================] - 0s 11us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 16/100\n",
      "24129/24129 [==============================] - 0s 11us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 17/100\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 18/100\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 19/100\n",
      "24129/24129 [==============================] - 0s 11us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 20/100\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 21/100\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 22/100\n",
      "24129/24129 [==============================] - 0s 11us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 23/100\n",
      "24129/24129 [==============================] - 0s 11us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 24/100\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 25/100\n",
      "24129/24129 [==============================] - 0s 14us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 26/100\n",
      "24129/24129 [==============================] - 0s 14us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 27/100\n",
      "24129/24129 [==============================] - 0s 15us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 28/100\n",
      "24129/24129 [==============================] - 0s 14us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 29/100\n",
      "24129/24129 [==============================] - 0s 13us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 30/100\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 31/100\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 32/100\n",
      "24129/24129 [==============================] - 0s 14us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 33/100\n",
      "24129/24129 [==============================] - 0s 13us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 34/100\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 35/100\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 36/100\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 37/100\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 4.0133 - acc: 0.7510: 0s - loss: 4.0281 - acc: 0.7\n",
      "Epoch 38/100\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 39/100\n",
      "24129/24129 [==============================] - 0s 11us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 40/100\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 41/100\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 42/100\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 43/100\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 44/100\n",
      "24129/24129 [==============================] - 0s 10us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 45/100\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 46/100\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 47/100\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 48/100\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 49/100\n",
      "24129/24129 [==============================] - 0s 11us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 50/100\n",
      "24129/24129 [==============================] - 0s 11us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 51/100\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 52/100\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 53/100\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 54/100\n",
      "24129/24129 [==============================] - 0s 11us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 55/100\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 56/100\n",
      "24129/24129 [==============================] - 0s 11us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 57/100\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 58/100\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 59/100\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 60/100\n",
      "24129/24129 [==============================] - 0s 11us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 61/100\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 62/100\n",
      "24129/24129 [==============================] - 0s 13us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 63/100\n",
      "24129/24129 [==============================] - 0s 13us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 64/100\n",
      "24129/24129 [==============================] - 0s 14us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 65/100\n",
      "24129/24129 [==============================] - 0s 15us/step - loss: 4.0133 - acc: 0.7510: 0s - loss: 4.0546 - acc: 0\n",
      "Epoch 66/100\n",
      "24129/24129 [==============================] - 0s 15us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 67/100\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 68/100\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 69/100\n",
      "24129/24129 [==============================] - 0s 14us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 70/100\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 71/100\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 72/100\n",
      "24129/24129 [==============================] - 0s 11us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 73/100\n",
      "24129/24129 [==============================] - 0s 11us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 74/100\n",
      "24129/24129 [==============================] - 0s 14us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 75/100\n",
      "24129/24129 [==============================] - 0s 14us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 76/100\n",
      "24129/24129 [==============================] - 0s 13us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 77/100\n",
      "24129/24129 [==============================] - 0s 13us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 78/100\n",
      "24129/24129 [==============================] - 0s 15us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 79/100\n",
      "24129/24129 [==============================] - 0s 16us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 80/100\n",
      "24129/24129 [==============================] - 0s 14us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 81/100\n",
      "24129/24129 [==============================] - 0s 13us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 82/100\n",
      "24129/24129 [==============================] - 0s 14us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 83/100\n",
      "24129/24129 [==============================] - 0s 11us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 84/100\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 85/100\n",
      "24129/24129 [==============================] - 0s 11us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 86/100\n",
      "24129/24129 [==============================] - 0s 11us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 87/100\n",
      "24129/24129 [==============================] - 0s 11us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 88/100\n",
      "24129/24129 [==============================] - 0s 11us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 89/100\n",
      "24129/24129 [==============================] - 0s 11us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 90/100\n",
      "24129/24129 [==============================] - 0s 11us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 91/100\n",
      "24129/24129 [==============================] - 0s 11us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 92/100\n",
      "24129/24129 [==============================] - 0s 11us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 93/100\n",
      "24129/24129 [==============================] - 0s 11us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 94/100\n",
      "24129/24129 [==============================] - 0s 11us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 95/100\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 96/100\n",
      "24129/24129 [==============================] - 0s 11us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 97/100\n",
      "24129/24129 [==============================] - 0s 11us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 98/100\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 99/100\n",
      "24129/24129 [==============================] - 0s 11us/step - loss: 4.0133 - acc: 0.7510\n",
      "Epoch 100/100\n",
      "24129/24129 [==============================] - 0s 11us/step - loss: 4.0133 - acc: 0.7510\n"
     ]
    }
   ],
   "source": [
    "# Set up the logistic regression model\n",
    "model = Sequential()\n",
    "model.add(Dense(2, input_dim=(13), kernel_initializer='normal', activation='softmax'))\n",
    "model.compile(optimizer=SGD(lr=0.05), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "print(model.summary())\n",
    "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6033/6033 [==============================] - 0s 24us/step\n",
      "0.7513674788761154\n"
     ]
    }
   ],
   "source": [
    "evaluation = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(evaluation[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[49.,  2., 12., ...,  0., 45., 38.],\n",
       "       [22.,  2., 15., ...,  0., 40., 38.],\n",
       "       [17.,  2.,  1., ...,  0., 15., 38.],\n",
       "       ...,\n",
       "       [36.,  1.,  8., ...,  0., 40., 38.],\n",
       "       [33.,  2.,  1., ...,  0., 40., 38.],\n",
       "       [39.,  2., 15., ...,  0., 40., 38.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "24129/24129 [==============================] - 1s 25us/step - loss: 1.5936 - acc: 0.6996\n",
      "Epoch 2/50\n",
      "24129/24129 [==============================] - 0s 13us/step - loss: 1.3111 - acc: 0.7399\n",
      "Epoch 3/50\n",
      "24129/24129 [==============================] - 0s 13us/step - loss: 1.2807 - acc: 0.7496\n",
      "Epoch 4/50\n",
      "24129/24129 [==============================] - 0s 14us/step - loss: 1.2601 - acc: 0.7545\n",
      "Epoch 5/50\n",
      "24129/24129 [==============================] - 0s 13us/step - loss: 1.2399 - acc: 0.7642\n",
      "Epoch 6/50\n",
      "24129/24129 [==============================] - 0s 13us/step - loss: 1.2312 - acc: 0.7673\n",
      "Epoch 7/50\n",
      "24129/24129 [==============================] - 0s 17us/step - loss: 1.2381 - acc: 0.7677\n",
      "Epoch 8/50\n",
      "24129/24129 [==============================] - 0s 14us/step - loss: 1.2278 - acc: 0.7703\n",
      "Epoch 9/50\n",
      "24129/24129 [==============================] - 0s 13us/step - loss: 1.2249 - acc: 0.7723\n",
      "Epoch 10/50\n",
      "24129/24129 [==============================] - 0s 13us/step - loss: 1.2240 - acc: 0.7723\n",
      "Epoch 11/50\n",
      "24129/24129 [==============================] - 0s 13us/step - loss: 1.2244 - acc: 0.7746\n",
      "Epoch 12/50\n",
      "24129/24129 [==============================] - 0s 14us/step - loss: 1.2282 - acc: 0.7741\n",
      "Epoch 13/50\n",
      "24129/24129 [==============================] - 0s 15us/step - loss: 1.2194 - acc: 0.7756\n",
      "Epoch 14/50\n",
      "24129/24129 [==============================] - 0s 15us/step - loss: 1.2183 - acc: 0.7759\n",
      "Epoch 15/50\n",
      "24129/24129 [==============================] - 0s 15us/step - loss: 1.2163 - acc: 0.7775\n",
      "Epoch 16/50\n",
      "24129/24129 [==============================] - 0s 14us/step - loss: 1.2170 - acc: 0.7771\n",
      "Epoch 17/50\n",
      "24129/24129 [==============================] - 0s 11us/step - loss: 1.2129 - acc: 0.7789\n",
      "Epoch 18/50\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 1.2099 - acc: 0.7801\n",
      "Epoch 19/50\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 1.2090 - acc: 0.7798\n",
      "Epoch 20/50\n",
      "24129/24129 [==============================] - 0s 14us/step - loss: 1.2085 - acc: 0.7809: 0s - loss: 1.2686 - acc: 0\n",
      "Epoch 21/50\n",
      "24129/24129 [==============================] - 0s 16us/step - loss: 1.2085 - acc: 0.7826\n",
      "Epoch 22/50\n",
      "24129/24129 [==============================] - 0s 19us/step - loss: 1.2050 - acc: 0.7836\n",
      "Epoch 23/50\n",
      "24129/24129 [==============================] - 0s 19us/step - loss: 1.2023 - acc: 0.7823\n",
      "Epoch 24/50\n",
      "24129/24129 [==============================] - 0s 17us/step - loss: 1.1975 - acc: 0.7850\n",
      "Epoch 25/50\n",
      "24129/24129 [==============================] - 0s 15us/step - loss: 1.2040 - acc: 0.7830\n",
      "Epoch 26/50\n",
      "24129/24129 [==============================] - 0s 14us/step - loss: 1.1961 - acc: 0.7855\n",
      "Epoch 27/50\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 1.1934 - acc: 0.7859\n",
      "Epoch 28/50\n",
      "24129/24129 [==============================] - 0s 11us/step - loss: 1.1898 - acc: 0.7854\n",
      "Epoch 29/50\n",
      "24129/24129 [==============================] - 0s 11us/step - loss: 1.1900 - acc: 0.7867\n",
      "Epoch 30/50\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 1.1851 - acc: 0.7866\n",
      "Epoch 31/50\n",
      "24129/24129 [==============================] - 0s 11us/step - loss: 1.1831 - acc: 0.7885\n",
      "Epoch 32/50\n",
      "24129/24129 [==============================] - 0s 10us/step - loss: 1.1804 - acc: 0.7874\n",
      "Epoch 33/50\n",
      "24129/24129 [==============================] - 0s 11us/step - loss: 1.1803 - acc: 0.7871\n",
      "Epoch 34/50\n",
      "24129/24129 [==============================] - 0s 11us/step - loss: 1.1778 - acc: 0.7894\n",
      "Epoch 35/50\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 1.1749 - acc: 0.7907\n",
      "Epoch 36/50\n",
      "24129/24129 [==============================] - 0s 11us/step - loss: 1.1751 - acc: 0.7898\n",
      "Epoch 37/50\n",
      "24129/24129 [==============================] - 0s 10us/step - loss: 1.1738 - acc: 0.7893\n",
      "Epoch 38/50\n",
      "24129/24129 [==============================] - 0s 10us/step - loss: 1.1702 - acc: 0.7905\n",
      "Epoch 39/50\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 1.1701 - acc: 0.7906\n",
      "Epoch 40/50\n",
      "24129/24129 [==============================] - 0s 11us/step - loss: 1.1699 - acc: 0.7898\n",
      "Epoch 41/50\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 1.1706 - acc: 0.7905\n",
      "Epoch 42/50\n",
      "24129/24129 [==============================] - 0s 11us/step - loss: 1.1692 - acc: 0.7900\n",
      "Epoch 43/50\n",
      "24129/24129 [==============================] - 0s 11us/step - loss: 1.1671 - acc: 0.7918\n",
      "Epoch 44/50\n",
      "24129/24129 [==============================] - 0s 11us/step - loss: 1.1687 - acc: 0.7909\n",
      "Epoch 45/50\n",
      "24129/24129 [==============================] - 0s 16us/step - loss: 1.1661 - acc: 0.7914\n",
      "Epoch 46/50\n",
      "24129/24129 [==============================] - 0s 11us/step - loss: 1.1655 - acc: 0.7935\n",
      "Epoch 47/50\n",
      "24129/24129 [==============================] - 0s 11us/step - loss: 1.1648 - acc: 0.7923\n",
      "Epoch 48/50\n",
      "24129/24129 [==============================] - 0s 11us/step - loss: 1.1639 - acc: 0.7941\n",
      "Epoch 49/50\n",
      "24129/24129 [==============================] - 0s 12us/step - loss: 1.1654 - acc: 0.7919\n",
      "Epoch 50/50\n",
      "24129/24129 [==============================] - 0s 11us/step - loss: 1.1638 - acc: 0.7932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x5a0386ba20>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# configs\n",
    "epochs = 50\n",
    "batch_size = 88\n",
    "output_classes = 2\n",
    "layer1 = 13\n",
    "layer2 = 12\n",
    "layer3 = 20\n",
    "\n",
    "# Set up the logistic regression model\n",
    "model = Sequential()\n",
    "model.add(Dense(layer2, input_dim=layer1, activation='relu'))\n",
    "model.add(Dense(layer3, activation='relu'))\n",
    "model.add(Dense(output_classes, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6033/6033 [==============================] - 0s 28us/step\n"
     ]
    }
   ],
   "source": [
    "evaluation = model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7849328692686928"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
